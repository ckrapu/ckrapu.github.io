<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Multivariate sample size for Markov chains | Christopher Krapu </title> <meta name="author" content="Christopher Krapu"> <meta name="description" content="Assessing effective sample size for multiple variates"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%81&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ckrapu.github.io/blog/2020/multivariate-sample-size-for-markov-chains/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Christopher</span> Krapu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">posts </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link"> search <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Multivariate sample size for Markov chains</h1> <p class="post-meta"> Created in February 18, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Summary: I show how to calculate a multivariate effective sample size after <a href="https://academic.oup.com/biomet/article/106/2/321/5426969" rel="external nofollow noopener" target="_blank">Vats et al. (2019)</a></strong>. In applied statistics, Markov chain Monte Carlo (MCMC) is now widely used to fit statistical models. Suppose we have a statistical model \(p_\theta\) of some dataset \(\mathcal{D}\) which has a parameter \(\theta\). The basic idea behind MCMC is to estimate \(\theta\) by generating \(N\) random variates \(\theta_i,\theta_2,...\) from the posterior distribution \(p(\theta\vert\mathcal{D})\) which are (hopefully) distributed around \(\theta\) in a predictable way. The Bayesian central limit theorem states that under the right conditions, \(\theta_i\) is normally distributed about the true parameter value \(\theta\) with some sample variance \(\sigma^2\). We might then want to use the mean of these samples \(\hat{\theta}=\sum_i^N \theta_i\) as an estimator of \(\theta\) since this <em>posterior mean</em> is an optimal estimator in the context of Bayes risk and mean square loss.</p> <p>This task has a few challenges lurking within. The accuracy of our estimate of \(\theta\) is going to be low when we have only a few samples, i.e. \(N\) is quite small. We can increase our accuracy by taking more samples. Ideally, our samples \(\theta_i\) are all going to be <em>independent</em> so that we can make use of the theory of Monte Carlo estimators to assert that the error in our estimation of \(\theta\) decreases at a rate of \(1/N\). Thus, to get more accuracy, we draw more samples!</p> <h2 id="autocorrelated-mcmc-draws">Autocorrelated MCMC draws</h2> <p>Unfortunately, MCMC won’t provide uncorrelated values of \(\theta_i\) because of its inherently sequential nature. These samples are going to have some autocorrelation \(\rho\) and it’s helpful to think of this autocorrelation as reduced the number of samples from a nominal \(N\) to an effective number \(N\). Here’s a helpful analogy - suppose that you want to determine the average income within a city. You could pursue two sampling strategies; the first leads you to travel to 10 spots randomly selected on the map and then query a single person. The second approach is that you travel to two neighborhoods and query five people each. The latter method has the downside that you may get grossly misrepresentative numbers if you happen to land in a neighborhood where everyone has similar incomes which are not close to the city-wide average. This is an example of <em>spatial</em> autocorrelation leading to poor estimation. The same underlying mechanism is at play with our MCMC estimator having reduced precision.</p> <p>The literature on sequential data makes frequent use to autocorrelations \(\rho_p\) of lag \(p\) meant to capture associations between data points with varying amounts of time or distance between them. We can provide a formula for the effective sample size in terms of these autocorrelations <a href="https://mc-stan.org/docs/2_22/reference-manual/effective-sample-size-section.html" rel="external nofollow noopener" target="_blank">(see here for more)</a> via the following formula: \(N_{eff} = \frac{N}{\sum_{t=-\infty}^{\infty}\rho_t}\)</p> <p>We truncate the sum in practice since the autocorrelations typically vanish after a large number of lags. Interestingly, the effective sample size also has another form which also implicitly involves autocorrelations. Suppose that we have a chain of samples \(\theta_1,...,\theta_N\) and partition this chain into two <em>batches</em> comprising the samples from \(1\) to \(N/2\) and from \(N/2\) to \(N\). If the samples are close to independent, then the per-batch means \(T_{(k)}\) should be relatively close to each other. If they aren’t, then the batches contain distinct subpopulations of samples. The key insight here is that if the subpopulations are distinct, then they exhibit high within-batch autocorrelation. Thus, we can attempt to back out the autocorrelations by looking at the differences between batch means! For $a\(batch means, each of size\)N/a$$, this produces the following quantity:</p> \[\lambda^2=\frac{N}{a(a-1)}\sum_k (T_{(k)}-\hat{\theta})^2\] <p>Then, if we take the ratio of this quantity with the overall sample variance \(\sigma^2\), we get another formula for the effective sample size:</p> \[N_{eff} = \frac{n\lambda^2}{\sigma^2}\] <h2 id="effective-sample-size-for-multivariate-draws">Effective sample size for multivariate draws</h2> <p>The aforementioned equations for the effective sample size are fine for draws of univariate quantities. We also want to know how to obtain an analogous number for vector-valued random processes. Researchers often attempt to do so by simply evaluating the scalar \(N_{eff}\) for each individual dimension of a chain of vector samples, but this isn’t very satisying. Fortunately, recent work by <a href="https://academic.oup.com/biomet/article/106/2/321/5426969" rel="external nofollow noopener" target="_blank">Dats et al. (2019)</a> has shown that a the straightforward multivariate generalization of the above formula works perfectly well! We simply have to generalize the quantities \(\lambda^2\) and \(\sigma^2\) to their matrix counterparts: \(\Lambda=\frac{N}{a(a-1)}\sum_k ({\vec{T}}_{(k)}-{\hat{\theta}})^T({\vec{T}}_{(k)}-\hat)\) \(\Sigma=\frac{1}{N-1}\sum_i ({\vec{\theta_i}}-{\hat{\theta}})^T({\vec{\theta_i}}^{(k)}-\hat)\) With these quantities, we write out the effective number of samples as before just with the matrix generalizations of all quantities involved. Note that here, \(p\) represents the dimension of \(\theta_i\).</p> \[N_{eff}^{multi} = N\left(\frac{\vert\Lambda\vert}{\vert\Sigma\vert}\right)^{1/p}\] <p>Note that you still need to choose how many batches are used - a rule-of-thumb (there are more technical conditions that are worth reading about, though) is to use a batch size of \(\sqrt{N}\), so if you have 256 samples then there would be 16 batches of 16 samples each.</p> <p>In the code below, I’ll show how to calculate this for a toy example.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">n</span>    <span class="o">=</span> <span class="mi">256</span> <span class="c1"># Number of draws
</span><span class="n">p</span>    <span class="o">=</span> <span class="mi">10</span>   <span class="c1"># Dimension of each draw
</span><span class="n">cov</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="c1"># True covariance matrix
</span><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="c1"># true mean vector
</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span><span class="n">cov</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="n">n_batches</span>         <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">n</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">samples_per_batch</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="n">n_batches</span><span class="p">)</span>

<span class="c1"># Split up data into batches and take averages over
# individual batches as well as the whole dataset
</span><span class="n">batches</span>     <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span><span class="n">samples_per_batch</span><span class="p">,</span><span class="n">p</span><span class="p">)</span>
<span class="n">batch_means</span> <span class="o">=</span> <span class="n">batches</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">full_mean</span>   <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Calculate the matrix lam as a sum of vector
# outer products
</span><span class="n">prefactor</span>       <span class="o">=</span> <span class="n">samples_per_batch</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_batches</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">batch_residuals</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_means</span> <span class="o">-</span> <span class="n">full_mean</span><span class="p">)</span>
<span class="n">lam</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>
    <span class="n">lam</span> <span class="o">+=</span> <span class="n">prefactor</span> <span class="o">*</span> <span class="p">(</span><span class="n">batch_residuals</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">*</span> <span class="n">batch_residuals</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,:].</span><span class="n">T</span><span class="p">)</span>

<span class="n">sigma</span> <span class="o">=</span>  <span class="n">np</span><span class="p">.</span><span class="nf">cov</span><span class="p">(</span><span class="n">samples</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">n_eff</span> <span class="o">=</span> <span class="n">n</span><span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">det</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">det</span><span class="p">(</span><span class="n">sigma</span><span class="p">))</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">p</span><span class="p">)</span>

</code></pre></div></div> <p>Let’s see what \(N_{eff}\) is for this case:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">There are {0} effective samples</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">n_eff</span><span class="p">)))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>There are 166 effective samples
</code></pre></div></div> <p>Since I used 256 truly independent samples in total, it appears that this statistic is somewhat conservative in reporting the effective sample size. I hope this was useful! Again, you can read more about this method at <a href="https://academic.oup.com/biomet/article/106/2/321/5426969" rel="external nofollow noopener" target="_blank">this Biometrika article</a> by Dootika Vats et al.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/density-estimation-for-geospatial-imagery-using-autoregressive-models/">Density estimation for geospatial imagery using autoregressive neural models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/clustering-for-prob-preterm-birth/">Modeling spatial structure in binary data with an H3 hexagonal coordinate system</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/creating-an-emulator-for-an-agent-based-model/">Surrogate modeling for SEIR dynamics</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/nonparametric-changepoint-model-pymc/">Modeling temporal data with an unknown number of changepoints</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/fast-matrix-vector-product-for-structured-matrices/">Fast Kronecker matrix-vector product with einsum</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Christopher Krapu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-posts",title:"posts",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-modeling-temporal-data-with-an-unknown-number-of-changepoints",title:"Modeling temporal data with an unknown number of changepoints",description:"A nonparametric changepoint model in PyMC",section:"Posts",handler:()=>{window.location.href="/blog/2022/nonparametric-changepoint-model-pymc/"}},{id:"post-distributed-zonal-averages-for-fast-geospatial-analyses",title:"Distributed zonal averages for fast geospatial analyses",description:"Easy local average with Google Earth Engine&#39;s Python API",section:"Posts",handler:()=>{window.location.href="/blog/2022/fast-local-summary-earth-engine/"}},{id:"post-fast-kronecker-matrix-vector-product-with-einsum",title:"Fast Kronecker matrix-vector product with einsum",description:"Easy local average with Google Earth Engine&#39;s Python API",section:"Posts",handler:()=>{window.location.href="/blog/2021/fast-matrix-vector-product-for-structured-matrices/"}},{id:"post-balanced-spatial-partitioning-for-point-data-in-20-lines",title:"Balanced spatial partitioning for point data in 20 lines",description:"Recursively splitting by boxes",section:"Posts",handler:()=>{window.location.href="/blog/2021/balanced-spatial-partitioning-for-point-data-in-20-lines/"}},{id:"post-modeling-spatial-structure-in-binary-data-with-an-h3-hexagonal-coordinate-system",title:"Modeling spatial structure in binary data with an H3 hexagonal coordinate system",description:"Conditional autoregression for 6-adjacent data",section:"Posts",handler:()=>{window.location.href="/blog/2021/clustering-for-prob-preterm-birth/"}},{id:"post-surrogate-modeling-for-seir-dynamics",title:"Surrogate modeling for SEIR dynamics",description:"Modeling a model, for epidemiology",section:"Posts",handler:()=>{window.location.href="/blog/2021/creating-an-emulator-for-an-agent-based-model/"}},{id:"post-density-estimation-for-geospatial-imagery-using-autoregressive-neural-models",title:"Density estimation for geospatial imagery using autoregressive neural models",description:"Conditional autoregression for 6-adjacent data",section:"Posts",handler:()=>{window.location.href="/blog/2020/density-estimation-for-geospatial-imagery-using-autoregressive-models/"}},{id:"post-multivariate-sample-size-for-markov-chains",title:"Multivariate sample size for Markov chains",description:"Assessing effective sample size for multiple variates",section:"Posts",handler:()=>{window.location.href="/blog/2020/multivariate-sample-size-for-markov-chains/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%6B%72%61%70%75@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ckrapu","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>