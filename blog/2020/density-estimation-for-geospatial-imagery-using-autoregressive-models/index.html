<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Density estimation for geospatial imagery using autoregressive neural models | Christopher Krapu </title> <meta name="author" content="Christopher Krapu"> <meta name="description" content="Conditional autoregression for 6-adjacent data"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%81&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ckrapu.github.io/blog/2020/density-estimation-for-geospatial-imagery-using-autoregressive-models/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Christopher</span> Krapu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">posts </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Density estimation for geospatial imagery using autoregressive neural models</h1> <p class="post-meta"> Created in March 30, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Bayesian machine learning is all about learning a good representation of very complicated datasets, leveraging cleverly structured models and effective parameter estimation techniques to create a high-dimensional probability distribution approximating the observed data. A key advantage of posing computer vision research under the umbrella of Bayesian inference is that some tasks become really straightforward with the right choice of model.</p> <p>In this notebook, I show how to use <strong>PixelCNN</strong>, a deep generative model of structured data, to perform density estimation on geospatial topographic imagery derived from LiDAR maps of the Earth’s surface. I also highlight how easy this is within TensorFlow Probability, a new open-source project extending the capabilities of Tensorflow into <strong>probabilistic programming</strong>, i.e. the representation of probability distributions with computer programs in a way that treats random variables as first-class citizens.</p> <p><strong>Note</strong>: To reproduce this notebook, you will need the digital elevation map dataset I used to train the model. It’s too large to be hosted on my Github repository. Email me at ckrapu at gmail.com to get everything you need to reproduce this!</p> <h3 id="density-estimation">Density estimation</h3> <p>Density estimation is a task which has a common sense interpretation: if our understanding of the world is encoded in a probabilistic model, data points with especially low density are <strong>rare</strong> according to the model while points with high density are <strong>common</strong>. Suppose that you are walking down the street and you see a bright, neon blue dog that is as large as a firetruck. This is an instance which would probably receive low density under your subjective model of the world because there is exceedingly low probability of it appearing. Conversely, a smaller brown dog would receive a higher density value because it is more likely under the set of beliefs and assumptions you hold about the world.</p> <p>Most probability distributions are not as rich or flexible as the set of beliefs that we individually hold about the world. Coming up with extremely flexible and rich distributions is an active area of research. As of right now, a leading approach to generating these distributions is via neural autoregressive models which extend standard time series models such as the autoregressive or ARIMA models to have a neural transition operation rather than a linear, Markovian operation. The <a href="https://arxiv.org/abs/1606.05328" rel="external nofollow noopener" target="_blank">PixelCNN architecture</a> is a popular neural autoregressive model currently in use.</p> <p>Many machine learning models of imagery do not allow for easy density estimation. For example, the variational autoencoder provides a mapping from latent variable \(\mathbf{z}\) to observed data point \(\mathbf{x}\). Unfortunately, calculating \(p(\mathbf{x})\) under the model typically requires approximating the integral \(p(\mathbf{x}) = \int_z p(\mathbf{x}\vert \mathbf{z})p(\mathbf{z}) d\mathbf{z}\). Autoregressive models, in their most basic form, just don’t have this latent variable representative and instead parameterize the function \(p(x_i \vert x_{i-1},...,x_1)\) where \(x_i\) denotes the \(i\)-th pixel in the image. This admits a decomposition of the image’s probability as \(p(\mathbf{x})=\prod_i p(x_i\vert x_{i-1},...,x_1)\). This assumes a total ordering of the pixels in an image; we usually assume the raster scan order (though there are <a href="https://arxiv.org/abs/1712.09763" rel="external nofollow noopener" target="_blank">creative solutions</a> which can improve on this!).</p> <p>The rest of this post shows how to use the PixelCNN distribution from Tensorflow Probability and apply density estimation. The PixelCNN distribution was included with the 0.9 update of <code class="language-plaintext highlighter-rouge">tensorflow-probability</code>, so you’ll need to upgrade your installation if you were on 0.8 or earlier.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="n">tensorflow_probability</span> <span class="k">as</span> <span class="n">tfp</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>


<span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">flatten_image_batch</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">This script uses Tensorflow </span><span class="si">{</span><span class="n">tf</span><span class="p">.</span><span class="n">__version__</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Tensorflow Probability version: </span><span class="si">{</span><span class="n">tfp</span><span class="p">.</span><span class="n">__version__</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This script uses Tensorflow 2.1.0
Tensorflow Probability version: 0.9.0
</code></pre></div></div> <p>The dataset that I’m using consists of images with dimension \(32\times32\times1\) representing topographical maps of the Earth’s surface in the state of North Dakota. Each pixel’s single channel of data represents the average elevation across several square meters. Features like roads, ditches, rivers and valleys can be seen in these images.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">../data/datasets/training/dem_32_filtered.npy</span><span class="sh">'</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">float32</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dem_as_int</span> <span class="o">=</span> <span class="p">(((</span><span class="n">data_numpy</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
</code></pre></div></div> <p>Currently, the available architectures for PixelCNN work best when the output data is quantized. The image data originally had pixel values within the rage \([-1,1]\) which need to be mapped to \(\{0,1,...,255\}\). Let’s take a look below and see what these images look like:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">selected</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">data_numpy</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="n">size</span><span class="o">=</span><span class="mi">36</span><span class="p">,</span><span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">dem_as_int</span><span class="p">[</span><span class="n">selected</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">32</span><span class="p">]</span>
<span class="n">flat</span> <span class="o">=</span> <span class="nf">flatten_image_batch</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(),</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">flat</span><span class="p">),</span> <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Training data</span><span class="sh">'</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">);</span>
</code></pre></div></div> <p><img src="/images/density-estimation-for-geospatial-imagery-using-autoregressive-models_files/density-estimation-for-geospatial-imagery-using-autoregressive-models_5_0.png" alt="png"></p> <p>Many of the images are of gently sloped or rolling surfaces with a few linear features such as ditches or roads. Many of the images have local regions of high variance corresponding to marshy vegetation which scatters the LiDAR pulses used for elevation estimation.</p> <p>The PixelCNN model is actually a joint distribution over all the pixels of an image. Thus, it was possible for the developers of the <code class="language-plaintext highlighter-rouge">tensorflow-probability</code> package to actually include it as one of their distributions! This makes it really easy to work with and the code below shows how little setup is required to train a PixelCNN with TFP. Much of this code was copied from the TFP documentation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Specify inputs and training settings
</span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">filters</span> <span class="o">=</span> <span class="mi">96</span>

<span class="c1"># Create a Tensorflow Dataset object
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">(</span><span class="n">dem_as_int</span><span class="p">)</span>
<span class="n">train_it</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="nf">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">data_numpy</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Create the PixelCNN using TFP
</span><span class="n">dist</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">PixelCNN</span><span class="p">(</span>
    <span class="n">image_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
    <span class="n">num_resnet</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_hierarchies</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">num_filters</span><span class="o">=</span><span class="n">filters</span><span class="p">,</span>
    <span class="n">num_logistic_mix</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">dropout_p</span><span class="o">=</span><span class="p">.</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Define the model input and objective function
</span><span class="n">image_input</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
<span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nf">log_prob</span><span class="p">(</span><span class="n">image_input</span><span class="p">)</span>

<span class="c1"># Specify model inputs and loss function
</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">image_input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">log_prob</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add_loss</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">log_prob</span><span class="p">))</span>
</code></pre></div></div> <p>Once the model is specified, we just need to compile it and start training. PixelCNN is an example of an autoregressive model and these are notorious for taking a long time to train. Unfortunately, I only have access to a single GPU currently. Normally, this code would display a progress bar and training metrics. I’ve toggled these off to keep the document short and prevent a large number of warnings from being shown.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Compile and train the model
</span><span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(.</span><span class="mi">001</span><span class="p">),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_it</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>WARNING:tensorflow:Output tf_op_layer_Reshape_3 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to tf_op_layer_Reshape_3.
Train for 4602 steps
Epoch 1/3
3626/4602 [======================&gt;.......] - ETA: 30:48 - loss: 2357.9549

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)



4602/4602 [==============================] - 8735s 2s/step - loss: 1989.1206
Epoch 3/3
 612/4602 [==&gt;...........................] - ETA: 2:06:25 - loss: 1972.0003
</code></pre></div></div> <p>Since we’ve created an approximation of a probability distribution, we can sample from it to see examples of points that have high density under the PixelCNN model. As a warning, this sampling procedure can take quite awhile.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mi">36</span><span class="p">)</span>
</code></pre></div></div> <p>Let’s visually compare the sampled values with ground truth data points.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">flatten_image_batch</span>

<span class="n">samples_numpy</span> <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">squeeze</span><span class="p">()</span>
<span class="n">flat_samples</span> <span class="o">=</span> <span class="nf">flatten_image_batch</span><span class="p">(</span><span class="n">samples_numpy</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">)),</span><span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">flat_samples</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Simulated images</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>

<span class="n">selected</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">data_numpy</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="n">size</span><span class="o">=</span><span class="mi">36</span><span class="p">,</span><span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">flat_ground_truth</span> <span class="o">=</span> <span class="nf">flatten_image_batch</span><span class="p">(</span><span class="n">data_numpy</span><span class="p">[</span><span class="n">selected</span><span class="p">].</span><span class="nf">squeeze</span><span class="p">(),</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">)),</span><span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">flat_ground_truth</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">True images</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">);</span>
</code></pre></div></div> <p><img src="/images/density-estimation-for-geospatial-imagery-using-autoregressive-models_files/density-estimation-for-geospatial-imagery-using-autoregressive-models_14_0.png" alt="png"></p> <p><img src="/images/density-estimation-for-geospatial-imagery-using-autoregressive-models_files/density-estimation-for-geospatial-imagery-using-autoregressive-models_14_1.png" alt="png"></p> <p>Both the ground truth and sampled images appear to show winding streams and sloping hillsides, though there are more linear features such as roads and ditches in the true data than the synthetic samples.</p> <p>In the next cell, I calculate the log density of 1000 ground truth images using the PixelCNN as my probability distribution. I also calculate the ranking of each image with regard to its probability.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">subset</span>    <span class="o">=</span> <span class="n">dem_as_int</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">log_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nf">log_prob</span><span class="p">(</span><span class="n">subset</span><span class="p">).</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">ranking</span>   <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">log_probs</span><span class="p">)</span>

<span class="n">sorted_log_prob</span> <span class="o">=</span> <span class="n">log_probs</span><span class="p">[</span><span class="n">ranking</span><span class="p">]</span>
</code></pre></div></div> <p>With these rankings, I can show images which have low, medium, or high density under the PixelCNN model</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span><span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">16</span><span class="p">))</span>
<span class="n">sorted_by_prob</span> <span class="o">=</span> <span class="n">subset</span><span class="p">[</span><span class="n">ranking</span><span class="p">]</span>

<span class="n">subsets</span> <span class="o">=</span> <span class="p">[</span><span class="n">sorted_by_prob</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">32</span><span class="p">],</span><span class="n">sorted_by_prob</span><span class="p">[</span><span class="mi">484</span><span class="p">:</span><span class="mi">516</span><span class="p">],</span><span class="n">sorted_by_prob</span><span class="p">[</span><span class="o">-</span><span class="mi">32</span><span class="p">:]]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Images with low density</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Images with medium density</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Images with high density</span><span class="sh">'</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">subset</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">subsets</span><span class="p">):</span>
    <span class="n">flat</span> <span class="o">=</span> <span class="nf">flatten_image_batch</span><span class="p">(</span><span class="n">subset</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(),</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">flat</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div> <p><img src="/images/density-estimation-for-geospatial-imagery-using-autoregressive-models_files/density-estimation-for-geospatial-imagery-using-autoregressive-models_19_0.png" alt="png"></p> <p>These images help us understand the representation that the model has learned. In the top panel, we see that the images with the lowest probability are those with a lot of “fuzziness”; these are images with lots of noisy LiDAR reflections due to water and vegetation. Since this is effectively random noise, it isn’t possible to predict perfectly what these values will be.</p> <p>Images with high density, on the other hand, show smoothly varying topography and very strong spatial autocorrelations. Again, this isn’t terribly surprising because the model has favored data points for which it can easily yield very good pixel-level predictions. If each pixel differs from its neighbor by only a small amount, it is much easier to construct a predictive model with low error.</p> <p>I hope that this provided a straightforward and minimal example of how to use Tensorflow Probability for a rather sophisticated machine learning task. I’ve been impressed with the functionality incorporated into the TFP codebase and look forward to using it more in the future!</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/nonparametric-changepoint-model-pymc/">Modeling temporal data with an unknown number of changepoints</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/clustering-for-prob-preterm-birth/">Modeling spatial structure in binary data with an H3 hexagonal coordinate system</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/creating-an-emulator-for-an-agent-based-model/">Surrogate modeling for SEIR dynamics</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/fast-matrix-vector-product-for-structured-matrices/">Fast Kronecker matrix-vector product with einsum</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/fast-local-summary-earth-engine/">Distributed zonal averages for fast geospatial analyses</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Christopher Krapu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-posts",title:"posts",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-modeling-temporal-data-with-an-unknown-number-of-changepoints",title:"Modeling temporal data with an unknown number of changepoints",description:"A nonparametric changepoint model in PyMC",section:"Posts",handler:()=>{window.location.href="/blog/2022/nonparametric-changepoint-model-pymc/"}},{id:"post-distributed-zonal-averages-for-fast-geospatial-analyses",title:"Distributed zonal averages for fast geospatial analyses",description:"Easy local average with Google Earth Engine&#39;s Python API",section:"Posts",handler:()=>{window.location.href="/blog/2022/fast-local-summary-earth-engine/"}},{id:"post-fast-kronecker-matrix-vector-product-with-einsum",title:"Fast Kronecker matrix-vector product with einsum",description:"Easy local average with Google Earth Engine&#39;s Python API",section:"Posts",handler:()=>{window.location.href="/blog/2021/fast-matrix-vector-product-for-structured-matrices/"}},{id:"post-balanced-spatial-partitioning-for-point-data-in-20-lines",title:"Balanced spatial partitioning for point data in 20 lines",description:"Recursively splitting by boxes",section:"Posts",handler:()=>{window.location.href="/blog/2021/balanced-spatial-partitioning-for-point-data-in-20-lines/"}},{id:"post-modeling-spatial-structure-in-binary-data-with-an-h3-hexagonal-coordinate-system",title:"Modeling spatial structure in binary data with an H3 hexagonal coordinate system",description:"Conditional autoregression for 6-adjacent data",section:"Posts",handler:()=>{window.location.href="/blog/2021/clustering-for-prob-preterm-birth/"}},{id:"post-surrogate-modeling-for-seir-dynamics",title:"Surrogate modeling for SEIR dynamics",description:"Modeling a model, for epidemiology",section:"Posts",handler:()=>{window.location.href="/blog/2021/creating-an-emulator-for-an-agent-based-model/"}},{id:"post-density-estimation-for-geospatial-imagery-using-autoregressive-neural-models",title:"Density estimation for geospatial imagery using autoregressive neural models",description:"Conditional autoregression for 6-adjacent data",section:"Posts",handler:()=>{window.location.href="/blog/2020/density-estimation-for-geospatial-imagery-using-autoregressive-models/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%6B%72%61%70%75@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ckrapu","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>